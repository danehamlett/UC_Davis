{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data | Log Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Part I - Splunk Analysis\n",
    "\n",
    "### What scenarios is Splunk appropriate for? Really well suited to?\n",
    "\n",
    "Splunk is a software product that enables searching, monitoring, and analyzing of machine-generated big data sets, through a web-faced interface<sup>1</sup>. It uses a standard API to connect directly to applications and devices, and was initially developed to meet the demand of supporting data-driven decision making for executives, without being dependent on an IT department. Splunk is able to connect to almost any log-based data feed, and they work with a variety of industries. They have three primary products (Splunk Enterprise, Splunk Cloud, and Splunk Light) which fit organizational needs relative to a respective source infrastructure, and data volume. Splunk also offers three primary services (Splunk IT Service Intelligence, Splunk Enterprise Security, and Splunk User Behavior Analytics), all servicing a wide array of IT and system-based analytic needs<sup>2</sup>.\n",
    "\n",
    "Splunk continues to increase market share, for several reasons. The primary reason why Splunk remains relevant, is that they offer a very mature product. The majority of their competitors are open-sourced (BMC, CA, Tivoli, Dynatrace), which may appeal to cost-cutting organizations<sup>3</sup>. However, the major fault of these products, is that they are not fully baked solutions. They each offer a fraction of services and functionality that Splunk does, and organizations will often spend more money bridging the gap between all of these disparate products, than they would through investing in Splunk.\n",
    "\n",
    "One example of Splunk in the 'real world', was how it's platform was applied to Domino's, to allow employees to access sales information, track sales performance, view customer satisfaction sentiments, understand order fulfillment speeds, and marketing promotion campaign effectiveness, in one centralized platform<sup>4</sup>.\n",
    "\n",
    "According to one Splunk user<sup>5</sup> . . . \n",
    "\n",
    "<strong>Good:</strong>\n",
    "\n",
    "1. Ad-hoc querying and analytics support.\n",
    "2. Defining the field extractor (allows for the creation fields from events) is a one-time exercise, which is then reusable.\n",
    "3. A highly mature product, which a large number of applications.\n",
    "4. Real-time availability of time-series data,\n",
    "5. Does offer a free version with limited functionality.\n",
    "6. Documentation and community forums are publically accessible.\n",
    "\n",
    "<strong>Bad:</strong>\n",
    "\n",
    "1. Searching large data sets can be time consuming, and resource intensive.\n",
    "2. As an index increases in size Windows CPU utilization may be excessive.\n",
    "3. The price for the paid version.\n",
    "<p></p>\n",
    "<p></p>\n",
    "<hr style=\"width:50%;\">\n",
    "<p></p>\n",
    "<p></p>\n",
    "<strong>Additional Splunk Componenets:</strong>\n",
    "\n",
    " - The Asset Investigator: shows malicious or possibly malicious content related to a particular asset searched by IP\n",
    " - Access Tracker: shows where the asset has connected and when the first access was\n",
    "\n",
    "<strong>Pricing:</strong>\n",
    " - You basically pay for how much data you’re using, if it’s over the 500mb/day limit on free users.\n",
    " - The more GB/day you use, you typically get a better bang for your buck\n",
    "     - Splunk pricing 100gb will cost around \\$1500\n",
    "     - Splunk pricing 10gb will cost \\$2500\n",
    "     - Splunk pricing 1gb will cost \\$4500\n",
    "\n",
    "\n",
    "#### References\n",
    "\n",
    "1. https://en.wikipedia.org/wiki/Splunk\n",
    "2. https://www.splunk.com/en_us/products.html\n",
    "3. https://www.infoworld.com/article/3180801/analytics/why-splunk-keeps-beating-open-source-competitors.html\n",
    "4. https://www.edureka.co/blog/splunk-use-case?utm_source=quora&utm_medium=crosspost&utm_campaign=social-media-edureka-pg\n",
    "5. https://www.quora.com/Whats-good-and-bad-about-Splunk\n",
    "6. https://government.diginomica.com/2017/10/30/splunk-pursuit-business-user/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II - Parsing Log Data\n",
    "\n",
    "### Import Libraries and Create Initial Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# Create a blank list\n",
    "results = []\n",
    "\n",
    "# Open log file\n",
    "with open('/Users/danehamlett/Desktop/School/Big Data/msnbc990928.seq', newline='') as inputfile:\n",
    "    for row in csv.reader(inputfile):\n",
    "        results.append(row)\n",
    "\n",
    "# Create primary data frame\n",
    "df = pd.DataFrame(results,columns=[\"Row\"])\n",
    "\n",
    "# Drop header rows\n",
    "df.drop(df.index[:7], inplace=True)\n",
    "\n",
    "# Calculate total rows\n",
    "tot_rec = len(df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Data Frames and Analyze Data\n",
    "\n",
    "#### What % of visitors visited a page of type 12 and page of type 17 in the same session?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>1 1 12 15 10 12 17 11 1 1 12 15 3 10 17 11 1 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>12 17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2361</th>\n",
       "      <td>1 1 14 14 14 14 14 14 14 14 14 14 14 14 14 14 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3126</th>\n",
       "      <td>1 10 1 17 1 12 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3204</th>\n",
       "      <td>1 12 1 17 1 3 1 10 1 1 12 12 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Row\n",
       "356   1 1 12 15 10 12 17 11 1 1 12 15 3 10 17 11 1 2...\n",
       "2153                                             12 17 \n",
       "2361  1 1 14 14 14 14 14 14 14 14 14 14 14 14 14 14 ...\n",
       "3126                                  1 10 1 17 1 12 1 \n",
       "3204                    1 12 1 17 1 3 1 10 1 1 12 12 1 "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a data frame to analyze\n",
    "a_df = df[df['Row'].str.contains('12') & df['Row'].str.contains('17')]\n",
    "\n",
    "# Preview data\n",
    "a_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execute Metric Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The % of visitors who visited a page of type 12 and page of type 17 in the same session is %0.2595 (2569/989818).\n"
     ]
    }
   ],
   "source": [
    "# Calculate metric and print result\n",
    "a_visit = (len(a_df)/tot_rec)*100\n",
    "print(\"The % of visitors who visited a page of type 12 and page of type 17 in the same session is \" + \n",
    "      \"%\" + str(round(a_visit,4)) + \" (\" + str(len(a_df)) + \"/\" + str(tot_rec) + \").\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What % of visitors visited a page of type 12 AFTER page a page of type 17 in the same session (the two page views do not need to be consecutive)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row</th>\n",
       "      <th>T_Position</th>\n",
       "      <th>S_Position</th>\n",
       "      <th>T_After_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>1 1 12 15 10 12 17 11 1 1 12 15 3 10 17 11 1 2...</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>12 17</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2361</th>\n",
       "      <td>1 1 14 14 14 14 14 14 14 14 14 14 14 14 14 14 ...</td>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3126</th>\n",
       "      <td>1 10 1 17 1 12 1</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3204</th>\n",
       "      <td>1 12 1 17 1 3 1 10 1 1 12 12 1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Row  T_Position  \\\n",
       "356   1 1 12 15 10 12 17 11 1 1 12 15 3 10 17 11 1 2...           4   \n",
       "2153                                             12 17            0   \n",
       "2361  1 1 14 14 14 14 14 14 14 14 14 14 14 14 14 14 ...          70   \n",
       "3126                                  1 10 1 17 1 12 1           12   \n",
       "3204                    1 12 1 17 1 3 1 10 1 1 12 12 1            2   \n",
       "\n",
       "      S_Position  T_After_S  \n",
       "356           16          0  \n",
       "2153           3          0  \n",
       "2361          80          0  \n",
       "3126           7          1  \n",
       "3204           7          0  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new data frame\n",
    "b_df = a_df[[\"Row\"]].copy()\n",
    "\n",
    "# Identify character positions\n",
    "b_df['T_Position'] = b_df['Row'].str.find('12')\n",
    "b_df['S_Position'] = b_df['Row'].str.find('17')\n",
    "\n",
    "# Identify relative positions\n",
    "b_df['T_After_S'] = b_df['T_Position'] > b_df['S_Position']\n",
    "b_df['T_After_S'] = b_df['T_After_S'].astype(int)\n",
    "\n",
    "# Preview data\n",
    "b_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execute Metric Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The % of visitors who visited a page of type 12 after a page of type 17 in the same session is %0.1181 (1169/989818).\n"
     ]
    }
   ],
   "source": [
    "# Calculate metric and print result\n",
    "b_visit = (sum(b_df['T_After_S'])/tot_rec)*100\n",
    "print(\"The % of visitors who visited a page of type 12 after a page of type 17 in the same session is \" + \n",
    "      \"%\" + str(round(b_visit,4)) + \" (\" + str(sum(b_df['T_After_S'])) + \"/\" + str(tot_rec) + \").\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise two common Python libraries were used: csv, and pandas.  The csv library was used to import the sequence data, importing sequence details row-by-row.  The Pandas library was then used to create a data frame that enabled a detailed analysis of the data.  The code was left in a verbose state intentionally, to ensure a working solution to the exercise was clear, and accurate.  This code can certainly be optimized and minimized, but the focus of this exercise was not to identify the most optimial approach."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
